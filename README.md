# ğŸ§  Mental Health Text Classification using BERT

This project aims to classify user-generated text into different mental health conditions using transformer-based models, specifically BERT. The model is fine-tuned on labeled text data and helps in early detection of mental health issues through Natural Language Processing (NLP).

## ğŸ¯ Objective

To develop an intelligent system that can detect mental health issues like anxiety, depression, etc., from written text using machine learningâ€”particularly BERT-based deep learning models.

## âš™ï¸ Tech Stack

- **Programming Language:** Python
- **Libraries & Frameworks:**
  - `pandas`, `numpy` â€“ Data manipulation
  - `matplotlib`, `seaborn` â€“ Visualization
  - `nltk`, `re` â€“ Text preprocessing
  - `scikit-learn` â€“ Evaluation metrics, preprocessing
  - `transformers (Hugging Face)` â€“ BERT model/tokenizer, training API
  - `torch` â€“ Backend for training
  - `imblearn` â€“ Random over-sampling to handle class imbalance
  - `joblib` â€“ Saving models (optional)

## ğŸ“ Dataset

- **Source:** Kaggle Dataset
- **File:** `Combined Data.csv`
- **Columns:** Text, Label (mental health issue category)

The dataset contains posts or messages labeled with various mental health conditions.

## ğŸ§¹ Preprocessing Steps

- Removal of stopwords using `nltk`
- Lowercasing and regex cleaning
- Label encoding for categories
- Oversampling using `RandomOverSampler` to balance classes

## ğŸ§  Model Details

- **Model:** `bert-base-uncased`
- **Tokenizer:** `BertTokenizer` from Hugging Face
- **Training:** Done using Hugging Face `Trainer` API
- **Training Arguments:**
  - Batch size
  - Epochs
  - Logging/Offline mode for W&B
- **Platform:** Compatible with GPU (e.g., Kaggle with NVIDIA Tesla T4)

## ğŸ“Š Evaluation

Each model is evaluated using:

- Confusion Matrix
- Classification Report
- Accuracy, Precision, Recall, F1-score

